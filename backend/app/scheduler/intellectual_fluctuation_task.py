from datetime import datetime, timedelta, date
from json import dumps
import app
from app.logger import logger
from app.models import IdentityEval
import requests
from sqlmodel import Session, select
from app.core.db import engine


def intellectual_fluctuation_task():
    # å‡†å¤‡æ•°æ®
    models = [
        {"model_id": "gpt-4.1-azure", "dataset_keys": ["AIME25"]},
        {"model_id": "gpt-4.1-mini", "dataset_keys": ["AIME25"]},
        {
            "model_id": "pinefield.us.anthropic.claude-3-5-sonnet-20241022-v2:0",
            "dataset_keys": [
                "AIME24",
                "AIME25",
                "GPQA_DIAMOND",
                "MMLU_PRO_LAW",
                "MMLU_PRO_BUSINESS",
                "MMLU_PRO_PHILOSOPHY",
                "LIVE_CODE_BENCH",
            ],
        },
        {
            "model_id": "grok-3-mini-beta-jiang",
            "dataset_keys": [
                "AIME24",
                "AIME25",
                "GPQA_DIAMOND",
                "MMLU_PRO_LAW",
                "MMLU_PRO_BUSINESS",
                "MMLU_PRO_PHILOSOPHY",
                "LIVE_CODE_BENCH",
            ],
        },
        {
            "model_id": "pinefield.us.anthropic.claude-3-7-sonnet-20250219-v1:0",
            "dataset_keys": [
                "AIME24",
                "AIME25",
                "GPQA_DIAMOND",
                "MMLU_PRO_LAW",
                "MMLU_PRO_BUSINESS",
                "MMLU_PRO_PHILOSOPHY",
                "LIVE_CODE_BENCH",
            ],
        },
        {
            "model_id": "o4-mini-jiang",
            "dataset_keys": [
                "AIME24",
                "AIME25",
                "GPQA_DIAMOND",
                "MMLU_PRO_LAW",
                "MMLU_PRO_BUSINESS",
                "MMLU_PRO_PHILOSOPHY",
                "LIVE_CODE_BENCH",
            ],
        },
    ]

    logger.info(f"å¯åŠ¨æ™ºåŠ›æ³¢åŠ¨ä»»åŠ¡ï¼Œæ¨¡åž‹æ•°ï¼š{len(models)}")

    # è®°å½•å·®å¼‚çš„æ¨¡åž‹æ•°æ®é›†åˆ†æ•°ï¼Œç­‰æ‰€æœ‰è®¡ç®—å®ŒæˆåŽç»Ÿè®¡ä¸€å‘é€é£žä¹¦æ¶ˆæ¯
    diff: dict[str, int | None] = {}

    with Session(engine) as session:
        # èŽ·å–æ¨¡åž‹è¯„æµ‹åˆ†æ•°
        for model in models:
            model_id = model["model_id"]
            dataset_keys = model["dataset_keys"]
            for dataset_key in dataset_keys:
                try:
                    # æŸ¥è¯¢æ¨¡åž‹ä»Šå¤©çš„åˆ†æ•°
                    today_query = select(IdentityEval).where(
                        IdentityEval.ai_model_id == model_id,
                        IdentityEval.dataset_key == dataset_key,
                        IdentityEval.date == date.today(),
                        IdentityEval.score != -1,
                    )
                    today_result = session.exec(today_query).first()

                    # å¦‚æžœä»Šå¤©æ²¡æœ‰åˆ†æ•°ï¼Œåˆ™è·³è¿‡
                    if not today_result:
                        diff[f"{model_id}/{dataset_key}"] = None
                        continue

                    # æŸ¥è¯¢æ¨¡åž‹ä¸Žæ•°æ®é›†çš„è¿‘ä¸‰å¤©çš„åˆ†æ•°
                    query = select(IdentityEval).where(
                        IdentityEval.ai_model_id == model_id,
                        IdentityEval.dataset_key == dataset_key,
                        IdentityEval.date >= date.today() - timedelta(days=3),
                        IdentityEval.date < date.today(),
                        IdentityEval.score != -1,
                    )
                    logger.debug(f"æŸ¥è¯¢æ¡ä»¶ï¼š{query}")
                    three_days_result = session.exec(query).all()
                    # åªæœ‰æ»¡ä¸‰å¤©æ¡ä»¶çš„åˆ†æ•°æ‰ç®—
                    if len(three_days_result) < 3:
                        diff[f"{model_id}/{dataset_key}"] = None
                        continue
                    # è®¡ç®—å‰ä¸‰å¤©åˆ†æ•°çš„å¹³å‡å€¼
                    mean_score = sum(r.score for r in three_days_result) / len(
                        three_days_result
                    )
                    # è®¡ç®—å½“å¤©åˆ†æ•°
                    current_score = today_result.score
                    # è®¡ç®—åˆ†æ•°å·®å¼‚
                    score_diff = abs(mean_score - current_score)
                    # è®¡ç®—å·®å¼‚ç™¾åˆ†æ¯”
                    diff_percent = score_diff / mean_score * 100
                    diff[f"{model_id}/{dataset_key}"] = int(diff_percent)
                except Exception as e:
                    logger.error(
                        f"{model_id}/{dataset_key}è¯„æµ‹åˆ†æ•°åŸºå‡†å€¼å·®å¼‚è®¡ç®—é”™è¯¯", e
                    )

    logger.info(f"æ™ºåŠ›æ³¢åŠ¨ä»»åŠ¡å®Œæˆï¼Œå·®å¼‚æ¨¡åž‹æ•°æ®é›†åˆ†æ•°ï¼š{diff}")
    messages = []
    for key, diff_percent in diff.items():
        if diff_percent is None:
            messages.append(f"ðŸŸ {key}: åŸºå‡†å€¼å·®å¼‚è®¡ç®—è·³è¿‡ï¼Œæ•°æ®ä¸è¶³")
        elif diff_percent < 5:
            messages.append(f"ðŸŸ¢{key}: {diff_percent}%")
        else:
            messages.append(f"ðŸ”´{key}: {diff_percent}%")
    _send_message_to_feishu("\r\n".join(messages))

def _send_message_to_feishu(message):
    # Send a message to Feishu
    headers = {
        "Content-Type": "application/json",
        "Accept": "application/json",
    }
    data = {
        "msg_type": "text",
        "content": {
            "text": f"è¯„æµ‹åˆ†æ•°åŸºå‡†å€¼å·®å¼‚: \r\n{message}",
        },
    }
    try:
        url = "https://open.feishu.cn/open-apis/bot/v2/hook/52d1469f-1fed-40ee-aa7b-39df5159c945" if app.settings.ENVIRONMENT != "local" else "https://open.feishu.cn/open-apis/bot/v2/hook/3fb5fbbe-37c0-4788-b6d4-5333f5c0a4d6"
        response = requests.post(url, headers=headers, data=dumps(data))
        response.raise_for_status()
    except requests.RequestException as e:
        print(f"Error sending message to Feishu: {e}")
